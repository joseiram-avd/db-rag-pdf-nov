{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad6718f-f488-41cd-ba18-261313eb94ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2e89bb63-9cdb-4494-9560-7e32c2f3c9aa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize MLflow for Experiment Tracking"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional, Generator\n",
    "import json\n",
    "import os\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n",
    "from databricks.sdk.service.serving import DataframeSplitInput\n",
    "\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatAgentChunk,\n",
    "    ChatContext\n",
    ")\n",
    "\n",
    "from databricks import agents\n",
    "from mlflow.models import ModelConfig\n",
    "from mlflow.models.resources import DatabricksServingEndpoint\n",
    "\n",
    "import uuid  # Add at top of file\n",
    "from uuid import UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e96e251b-b030-49a6-8c22-eb33aee6f2ba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Installed Databricks Packages Overview"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-agents databricks-sdk mlflow databricks-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6874380e-eae7-4d84-9c63-4b52cf38f013",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize and Define Invoice Processing Agent"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile invoice_agent.py\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional, Generator\n",
    "import json\n",
    "import os\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n",
    "from databricks.sdk.service.serving import DataframeSplitInput\n",
    "\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatAgentChunk,\n",
    "    ChatContext\n",
    ")\n",
    "\n",
    "from databricks import agents\n",
    "from mlflow.models import ModelConfig\n",
    "from mlflow.models.resources import DatabricksServingEndpoint\n",
    "\n",
    "import uuid  # Add at top of file\n",
    "from uuid import UUID\n",
    "\n",
    "class InvoiceProcessingAgent(ChatAgent):\n",
    "# class InvoiceProcessingAgent(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def __init__(self, endpoint_name: str = \"databricks-claude-3-7-sonnet\"):\n",
    "        \"\"\"\n",
    "        Initialize the Invoice Processing Agent.\n",
    "        \n",
    "        Args:\n",
    "            endpoint_name: Name of the Databricks Foundation Model endpoint to use\n",
    "        \"\"\"\n",
    "        self.endpoint_name = endpoint_name\n",
    "        self.workspace_client = WorkspaceClient()\n",
    "        self.prompts = self._load_static_prompts()\n",
    "        \n",
    "        # Initialize OpenAI client for the foundation model\n",
    "        self.openai_client = self.workspace_client.serving_endpoints.get_open_ai_client()\n",
    "        \n",
    "        # Configure agent parameters\n",
    "        self.config = ModelConfig(development_config={\n",
    "            \"endpoint_name\": endpoint_name,\n",
    "            \"temperature\": 0.0,\n",
    "            \"max_tokens\": 4096\n",
    "        })\n",
    "    \n",
    "    def _load_static_prompts(self) -> Dict[str, str]:\n",
    "        \"\"\"Load the prompts from JSON\"\"\"\n",
    "        prompts = {\n",
    "            \"document_classification\": \"Classify this document into one of the following categories: invoice, receipt, ID, contract.\",\n",
    "            \"information_extraction\": \"Extract the following fields from this document: date, total amount, vendor name, transaction ID.\"\n",
    "        }\n",
    "        return prompts\n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None\n",
    "    ) -> ChatAgentResponse:\n",
    "        \"\"\"\n",
    "        Process a user query and return a response according to ChatAgent interface.\n",
    "        \n",
    "        Args:\n",
    "            messages: List of ChatAgentMessage objects\n",
    "            context: Optional ChatContext object\n",
    "            custom_inputs: Optional additional inputs\n",
    "            \n",
    "        Returns:\n",
    "            ChatAgentResponse containing the agent's response\n",
    "        \"\"\"\n",
    "        # Add unique ID\n",
    "        message_id = str(uuid.uuid4())\n",
    "\n",
    "        # Extract document text from the user message\n",
    "        user_messages = [msg for msg in messages if msg.role == \"user\"]\n",
    "        if not user_messages:\n",
    "            return ChatAgentResponse(messages=[\n",
    "                ChatAgentMessage(id=message_id, role=\"assistant\", content=\"Please provide a document to process.\")\n",
    "            ])\n",
    "        \n",
    "        document_text = user_messages[-1].content\n",
    "        \n",
    "        # Process the document\n",
    "        document_class = self._classify_document(document_text)\n",
    "        extracted_info = self._extract_information(document_text)\n",
    "        \n",
    "        # Format the response\n",
    "        result = {\n",
    "            \"document_class\": document_class,\n",
    "            \"extracted_information\": extracted_info\n",
    "        }\n",
    "        \n",
    "        # Create and return the agent response\n",
    "        return ChatAgentResponse(messages=[\n",
    "            ChatAgentMessage(\n",
    "                id=message_id,\n",
    "                role=\"assistant\", \n",
    "                content=f\"Document classified as: {document_class}\\n\\nExtracted information: {json.dumps(extracted_info, indent=2)}\"\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        \"\"\"\n",
    "        Stream the response for a user query according to ChatAgent interface.\n",
    "        \n",
    "        Args:\n",
    "            messages: List of ChatAgentMessage objects\n",
    "            context: Optional ChatContext object\n",
    "            custom_inputs: Optional additional inputs\n",
    "            \n",
    "        Yields:\n",
    "            ChatAgentChunk objects containing parts of the response\n",
    "        \"\"\"\n",
    "        message_id = str(uuid.uuid4())\n",
    "\n",
    "        # Extract document text from the user message\n",
    "        user_messages = [msg for msg in messages if msg.role == \"user\"]\n",
    "        if not user_messages:\n",
    "            yield ChatAgentChunk(delta=ChatAgentMessage(\n",
    "                id=message_id, \n",
    "                role=\"assistant\", \n",
    "                content=\"Please provide a document to process.\"\n",
    "            ))\n",
    "            return\n",
    "        \n",
    "        document_text = user_messages[-1].content\n",
    "        \n",
    "        # Process the document (in real implementation, this would be streamed)\n",
    "        document_class = self._classify_document(document_text)\n",
    "        \n",
    "        # Yield the classification result\n",
    "        yield ChatAgentChunk(delta=ChatAgentMessage(\n",
    "            id=message_id, \n",
    "            role=\"assistant\", \n",
    "            content=f\"Document classified as: {document_class}\\n\\n\"\n",
    "        ))\n",
    "        \n",
    "        # Process and yield the extraction result\n",
    "        extracted_info = self._extract_information(document_text)\n",
    "        yield ChatAgentChunk(delta=ChatAgentMessage(\n",
    "            id=message_id, \n",
    "            role=\"assistant\", \n",
    "            content=f\"Extracted information: {json.dumps(extracted_info, indent=2)}\"\n",
    "        ))\n",
    "    \n",
    "    def _classify_document(self, document_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Classify the document using foundation model.\n",
    "        \"\"\"\n",
    "        classification_prompt = self.prompts[\"document_classification\"]\n",
    "        \n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=self.endpoint_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert document classifier.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{classification_prompt}\\n\\nDocument: {document_text}\"}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=256\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    def _extract_information(self, document_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract information from the document using foundation model.\n",
    "        \"\"\"\n",
    "        extraction_prompt = self.prompts[\"information_extraction\"]\n",
    "        \n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=self.endpoint_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert at extracting structured information from documents. Return the information in JSON format.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{extraction_prompt}\\n\\nDocument: {document_text}\"}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Try to parse as JSON\n",
    "            return json.loads(response.choices[0].message.content)\n",
    "        except json.JSONDecodeError:\n",
    "            # If not valid JSON, return as text\n",
    "            return {\"raw_extraction\": response.choices[0].message.content.strip()}\n",
    "\n",
    "\n",
    "AGENT = InvoiceProcessingAgent()\n",
    "\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70eba517-1a8f-4444-85ca-1087bf9fcb5a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Log and Deploy MLflow Model with Databricks Tools"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# from getting_started_agent import LLM_ENDPOINT, baseline_config, tools\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "from invoice_agent import InvoiceProcessingAgent\n",
    "\n",
    "# TODO fill in your catalog and schema name\n",
    "# catalog = \"demos\"\n",
    "# schema = \"z_agents_002\"\n",
    "\n",
    "# TODO: Replace with your model serving endpoint\n",
    "LLM_ENDPOINT = \"databricks-claude-3-7-sonnet\"\n",
    "\n",
    "baseline_config = {\n",
    "    \"endpoint_name\": LLM_ENDPOINT,\n",
    "    \"temperature\": 0.00,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"system_prompt\": \"You are an expert document classifier and expert at extracting structured information from documents. Return the information in JSON format.\"\n",
    "}\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name='databricks-claude-3-7-sonnet')]\n",
    "\n",
    "tools = []\n",
    "\n",
    "for tool in tools:\n",
    "    if isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=\"invoice_agent.py\",\n",
    "        artifact_path=\"invoice_agent\",\n",
    "        model_config=baseline_config,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"databricks-agents\",\n",
    "            \"databricks-sdk\",\n",
    "            \"databricks-openai\",\n",
    "            \"langchain\",\n",
    "            \"langgraph==0.3.4\",\n",
    "            \"databricks-langchain\",\n",
    "            \"unitycatalog-langchain[databricks]\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        input_example={\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"INVOICE #123\\nDate: 2024-01-01\\nTotal: $100.00\"}]\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3b7133-cca7-4c65-8b8a-468284b90f04",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Register and Deploy New ML Model in Unity Catalog"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks import agents\n",
    "\n",
    "# Connect to the Unity catalog model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog and schema for your UC model\n",
    "catalog = \"demos2025\"\n",
    "schema = \"source_files\"\n",
    "\n",
    "assert (catalog and schema)\n",
    "\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.invoice_agent\"\n",
    "\n",
    "# Register to Unity catalog\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=model_info.model_uri, name=UC_MODEL_NAME\n",
    ")\n",
    "\n",
    "# Deploy to enable the review app and create an API endpoint\n",
    "deployment_info = agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e87fe3fe-8ae7-479b-bd45-44e8422cfd1c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Agent Initialization and Document Processing Example"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage in a Databricks notebook\n",
    "from invoice_agent import InvoiceProcessingAgent\n",
    "\n",
    "def main():\n",
    "    # Create an instance of the agent for direct usage\n",
    "    agent = InvoiceProcessingAgent(endpoint_name=\"databricks-claude-3-7-sonnet\")\n",
    "    \n",
    "    # Example document text\n",
    "    document_text = \"\"\"\n",
    "    INVOICE\n",
    "    \n",
    "    Invoice #: INV-2023-1234\n",
    "    Date: 2023-11-15\n",
    "    \n",
    "    Vendor: ABC Office Supplies\n",
    "    Customer: XYZ Corporation\n",
    "    \n",
    "    Items:\n",
    "    - Office paper (10 reams): $45.00\n",
    "    - Printer ink cartridges (2): $65.00\n",
    "    - Desk organizers (5): $25.00\n",
    "    \n",
    "    Subtotal: $135.00\n",
    "    Tax (10%): $13.50\n",
    "    Total: $148.50\n",
    "    \n",
    "    Payment due within 30 days.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process the document using ChatAgent interface\n",
    "    result = agent.predict([\n",
    "        ChatAgentMessage(role=\"user\", content=document_text)\n",
    "    ])\n",
    "    \n",
    "    # Print the result\n",
    "    print(result.messages[0].content)\n",
    "    \n",
    "    # Deploy the agent if needed\n",
    "    # deployment = deploy_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee631051-069f-451d-8f90-016eeac87ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Step 4-1 InvoiceProcessingAgent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
